## GP、Hadoop、Elk的原理区别

### 存储模型
hadoop是hdfs，扩展是通过元数据来做的，中心节点用来存元数据，在加入新的节点的时候，只需要修改元数据就可以了，所以hdfs的扩展能力是受到管理元数据那台机器的性能限制的。

mpp通常采用的是没有中心节点的存储模型，比如hash，你每次增加节点的时候，都需要rehash，这样当规模到了几百台的时候，扩展能力就下来了

### 内存管理方式
mpp内存管理比较精细，他主要的想法是在每个机器上放个数据库，传统数据库的内存管理比较复杂，主要是内外存交互的东西，这样的架构决定了mpp在小数据量的时候，延迟可以做的比较小，但是在大数据量的时候，吞吐量做不上去。

hive的内存管理非常粗放，他后来就是mapreduce的job，mr的job是没有太多精细的内存管理的，他就是拼了命地scan，完了顶多就是个spill，这样的架构导致throughput很大，但是latency很高，当你集群规模很大的时候，你一般会追求很大的throughput

当数据量很大的时候，如果你用mpp那种传统的内存管理的话，大批量的计算反而会慢，而且更加占资源。

### 事务
hive不支持传统意义上的那种高并发的事务

一旦你要上分布式事务，基本上你的可扩展性就上不去了

### failover机制，
hive的failover就是mr的failover，job挂掉了重新换机器跑就完了，但是mpp如果采用传统架构的话，他的计算是要attach到数据节点上去的，如果你规模上去，那么fail的可能性就上去了，这样如果你每次计算都有台机器挂了，你一挂，别人就要等你，而不是换台机器继续跑，那么这个也限制了可扩展性，当然，如果mpp在底层用了统一的存储，完了计算也可以到处转移，再想个办法把中间状态记录下来，也可以扩展（这个实际上就是sparksql）


***

###扩展性

MPP DB 还是基于原 DB 扩展而来， DB 里面天然追求一致性（ Consistency ），必然带来分区容错性较差。集群规模变得太大，业务数据太多时， MPP DB 的元数据管理就完全是一个灾难。元数据巨大无比，一旦出错很难恢复，动不动导致毁库。

所以 MPP DB 要在扩展性上有质的提示，要对元数据，以及数据存储有架构上的突破，降低对一致性的要求，这样扩展性才能提升，否则的话很难相信一个 MPP DB 数据库是可以容易扩展的

### 并发

一个查询系统，设计出来就是提供人用的，所以能支持的同时并发越高越好。MPP DB 核心原理是一 个大的查询通过分析为一一个子查询，分布到底层的执行，最后再合并结果，说白了就是通过多线程并发来暴力 SCAN 来实现高速。 这种暴力SCAN的方法，对单个查询来说，动用了整个系统的能力，单个查询比较快，但同时带来用力过猛的问题，整个系统能支持的并发必然不高，从目前实际使用的经验来说，也就支持50～100的并发能力。

***

hadoop 和 mpp 的本质区别是：就是什么时候解决 data locality的问题
hadoop 的思路是每次计算的时候解决，mpp的思路是加载的时候解决。

从查询引擎看，由于数据库支持索引，查询性能应该优于HADOOP。但是对于PB级别的数据，无法给所有维度的查询建立索引，主要靠全表扫描。因'此对于复杂查询，MPP并不比HADOOP特别是现在的SPARK方案体现出优势，而且架不住Hadoop集群机器多。